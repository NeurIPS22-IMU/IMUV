{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: tensorflow-probability==0.15.0 in /usr/local/lib/python3.8/dist-packages (0.15.0)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.10.0 in /usr/lib/python3/dist-packages (from tensorflow-probability==0.15.0) (1.14.0)\n",
      "Requirement already satisfied, skipping upgrade: cloudpickle>=1.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow-probability==0.15.0) (2.1.0)\n",
      "Requirement already satisfied, skipping upgrade: decorator in /usr/local/lib/python3.8/dist-packages (from tensorflow-probability==0.15.0) (5.1.0)\n",
      "Requirement already satisfied, skipping upgrade: dm-tree in /usr/local/lib/python3.8/dist-packages (from tensorflow-probability==0.15.0) (0.1.7)\n",
      "Requirement already satisfied, skipping upgrade: absl-py in /usr/local/lib/python3.8/dist-packages (from tensorflow-probability==0.15.0) (0.15.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow-probability==0.15.0) (1.21.3)\n",
      "Requirement already satisfied, skipping upgrade: gast>=0.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow-probability==0.15.0) (0.4.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 22.1.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already up-to-date: tensorflow-io in /usr/local/lib/python3.8/dist-packages (0.26.0)\n",
      "Requirement already satisfied, skipping upgrade: tensorflow-io-gcs-filesystem==0.26.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-io) (0.26.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 22.1.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already up-to-date: tensorflow_model_optimization in /usr/local/lib/python3.8/dist-packages (0.7.2)\n",
      "Requirement already satisfied, skipping upgrade: six~=1.10 in /usr/lib/python3/dist-packages (from tensorflow_model_optimization) (1.14.0)\n",
      "Requirement already satisfied, skipping upgrade: dm-tree~=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow_model_optimization) (0.1.7)\n",
      "Requirement already satisfied, skipping upgrade: numpy~=1.14 in /usr/local/lib/python3.8/dist-packages (from tensorflow_model_optimization) (1.21.3)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 22.1.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -U tensorflow-probability==0.15.0 \n",
    "!pip install -U tensorflow-io\n",
    "!pip install -U tensorflow_model_optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-26T02:32:39.743506Z",
     "iopub.status.busy": "2022-01-26T02:32:39.742922Z",
     "iopub.status.idle": "2022-01-26T02:32:41.587375Z",
     "shell.execute_reply": "2022-01-26T02:32:41.587817Z"
    },
    "id": "WZKbyU2-AiY-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.0\n",
      "/device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import tensorflow_io as tfio\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "\n",
    "device_name = tf.test.gpu_device_name()\n",
    "print(tf.__version__)\n",
    "print(device_name)\n",
    "tf.config.run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-26T02:32:41.608205Z",
     "iopub.status.busy": "2022-01-26T02:32:41.603269Z",
     "iopub.status.idle": "2022-01-26T02:32:49.530847Z",
     "shell.execute_reply": "2022-01-26T02:32:49.531240Z"
    },
    "id": "YzTlj4YdCip_"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy import signal\n",
    "import librosa\n",
    "import datetime\n",
    "import random\n",
    "import math\n",
    "from tensorflow.keras import layers\n",
    "import time\n",
    "import inspect\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "from scipy.io.wavfile import write\n",
    "\n",
    "from tensorflow.keras.layers import Conv2D, Input, LeakyReLU, UpSampling2D, Flatten, Dropout, Dense, Reshape, Conv2DTranspose, BatchNormalization, Activation, MaxPooling2D\n",
    "from tensorflow.keras import Model, Sequential, initializers # Data Generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(256)\n",
    "np.random.seed(256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3CH_1LFwtJ6b"
   },
   "source": [
    "# Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "snr_dB = 5\n",
    "sampling_rate = 4000\n",
    "\n",
    "def awgn(sinal, noise_signal):\n",
    "    regsnr=snr_dB\n",
    "    sigpower=sum([math.pow(abs(sinal[i]),2) for i in range(len(sinal))])\n",
    "    sigpower=sigpower/len(sinal)\n",
    "    sig_dB = 10* math.log(sigpower, 10)\n",
    "    noise_dB = sig_dB-snr_dB\n",
    "    noisescale= (math.pow(10,noise_dB/20))\n",
    "    npower=sum([math.pow(abs(noise_signal[i]),2) for i in range(len(noise_signal))])\n",
    "    npower=math.sqrt(npower/len(noise_signal))\n",
    "    noise=noisescale*noise_signal/npower\n",
    "    return noise\n",
    "\n",
    "def get_stft(x, fs, n_fft, hop_length, only_real=True):\n",
    "    c_stft = librosa.stft(x, n_fft=n_fft, hop_length=hop_length)\n",
    "    if only_real:\n",
    "        return np.abs(c_stft)\n",
    "    else:\n",
    "        return c_stft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tf/notebooks/IMUV_New\n"
     ]
    }
   ],
   "source": [
    "volunteer_id = 1\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "print(currentdir)\n",
    "clean_dir = \"../Dataset/Interfered/Volunteer\"+str(volunteer_id)\n",
    "checkpoint_dir = './volunteer_'+str(volunteer_id)+'_training_checkpoints'\n",
    "cycle_checkpoint_dir = './volunteer_'+str(volunteer_id)+'_cycle_training_checkpoints'\n",
    "\n",
    "output_parent_folder_name = \"volunteer_\"+str(volunteer_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## read the files. \n",
    "with (open(os.path.join(clean_dir, \"target_train.p\"), \"rb\")) as target_train_file:\n",
    "    all_train_mic_time, _, all_train_mic_stft, all_train_imu_stft, all_train_labels = pickle.load(target_train_file)\n",
    "with (open(os.path.join(clean_dir, \"target_test.p\"), \"rb\")) as target_test_file:\n",
    "    all_test_mic_time, _, all_test_mic_stft, all_test_imu_stft, all_test_labels = pickle.load(target_test_file)\n",
    "with (open(os.path.join(clean_dir, \"noise_train.p\"), \"rb\")) as noise_train_file:\n",
    "    all_train_noise_time, _, all_train_noise_labels = pickle.load(noise_train_file)\n",
    "with (open(os.path.join(clean_dir, \"noise_test.p\"), \"rb\")) as noise_test_file:\n",
    "    all_test_noise_time, _, all_test_noise_labels = pickle.load(noise_test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 33, 10, 4000) (1, 33, 10, 201, 21) (1, 33, 10, 21, 21)\n",
      "(1, 6, 10, 4000) (1, 6, 10, 201, 21) (1, 6, 10, 21, 21)\n",
      "(24, 500, 4000)\n",
      "(6, 500, 4000)\n"
     ]
    }
   ],
   "source": [
    "print(all_train_mic_time.shape, all_train_mic_stft.shape, all_train_imu_stft.shape)\n",
    "print(all_test_mic_time.shape, all_test_mic_stft.shape, all_test_imu_stft.shape)\n",
    "print(all_train_noise_time.shape)\n",
    "print(all_test_noise_time.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3520000 75000\n"
     ]
    }
   ],
   "source": [
    "# read combination files\n",
    "with (open(os.path.join(clean_dir, \"combination_index_train.p\"), \"rb\")) as index_train_file:\n",
    "    train_indexes = pickle.load(index_train_file)\n",
    "with (open(os.path.join(clean_dir, \"combination_index_test.p\"), \"rb\")) as index_test_file:\n",
    "    test_indexes = pickle.load(index_test_file)\n",
    "    \n",
    "print(len(train_indexes), len(test_indexes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_gen(batch_size, ftype = \"train\", real_output = True, onlyAudio = False, batch_ind = 0):\n",
    "    if ftype==\"train\":\n",
    "        all_mic_time = all_train_mic_time\n",
    "        all_mic_stft = all_train_mic_stft\n",
    "        all_imu_stft = all_train_imu_stft\n",
    "        all_noise_time = all_train_noise_time\n",
    "        all_target_labels = all_train_labels\n",
    "        all_noise_labels = all_train_noise_labels\n",
    "        all_indexes = train_indexes\n",
    "        t_noise_max = all_train_noise_time.shape[0]-1\n",
    "    else:\n",
    "        all_mic_time = all_test_mic_time\n",
    "        all_mic_stft = all_test_mic_stft\n",
    "        all_imu_stft = all_test_imu_stft\n",
    "        all_noise_time = all_test_noise_time\n",
    "        all_target_labels = all_test_labels\n",
    "        all_noise_labels = all_test_noise_labels\n",
    "        all_indexes = test_indexes\n",
    "        t_noise_max = all_test_noise_time.shape[0]-1\n",
    "\n",
    "    indxs = all_indexes[batch_size*batch_ind: batch_size*batch_ind + batch_size]\n",
    "    indxs = np.asarray(indxs)\n",
    "\n",
    "    noisy_arr_stft = []\n",
    "    target_arr_mic_stft = []\n",
    "    target_arr_imu_stft = []\n",
    "    label_arr = []\n",
    "    noise_arr = []\n",
    "    target_mic_arr = []\n",
    "    noisy_mic_arr = []\n",
    "\n",
    "    for ind in indxs:\n",
    "        temp_noise_time = all_noise_time[ind[1][0]][ind[1][1]]\n",
    "        temp_noise_labels = all_noise_labels[ind[1][0]][ind[1][1]]\n",
    "        temp_mic_time = all_mic_time[ind[0][0]][ind[0][1]][ind[0][2]]\n",
    "        temp_mic_stft = all_mic_stft[ind[0][0]][ind[0][1]][ind[0][2]]\n",
    "        temp_imu_stft = all_imu_stft[ind[0][0]][ind[0][1]][ind[0][2]]\n",
    "        temp_target_labels = all_target_labels[ind[0][0]][ind[0][1]][ind[0][2]]\n",
    "\n",
    "        scaled_noise = awgn(temp_mic_time, temp_noise_time)\n",
    "        roll_idx = random.randint(scaled_noise.shape[0]//2, scaled_noise.shape[0])\n",
    "        scaled_noise_r = np.roll(scaled_noise, roll_idx)\n",
    "        noisy_time = np.add(temp_mic_time, scaled_noise_r)\n",
    "        \n",
    "#         for i_inter in range(0, 4):\n",
    "#             t_n = all_noise_time[random.randint(0, t_noise_max)][random.randint(0, 400)]\n",
    "#             t_scaled_noise = awgn(temp_mic_time, t_n)\n",
    "#             t_roll_idx = random.randint(0, t_scaled_noise.shape[0])\n",
    "#             t_scaled_noise_r = np.roll(t_scaled_noise, t_roll_idx)\n",
    "#             noisy_time = np.add(noisy_time, t_scaled_noise_r)\n",
    "        \n",
    "        temp = get_stft(noisy_time, fs=noisy_time.shape[0], n_fft=400, hop_length=200, only_real=False)\n",
    "        temp = temp[1:201, :]\n",
    "        \n",
    "        temp_mic_stft = temp_mic_stft[1:201, :]\n",
    "        temp_imu_stft = temp_imu_stft[1:21, :]\n",
    "        \n",
    "        noisy_mic_arr.append(noisy_time)\n",
    "        noisy_arr_stft.append(temp)\n",
    "        target_mic_arr.append(temp_mic_time)\n",
    "        noise_arr.append(scaled_noise_r)\n",
    "        target_arr_mic_stft.append(temp_mic_stft)\n",
    "        target_arr_imu_stft.append(temp_imu_stft)\n",
    "        label_arr.append([temp_target_labels, temp_noise_labels])\n",
    "\n",
    "    noisy_arr_stft = np.asarray(noisy_arr_stft)\n",
    "    target_arr_mic_stft = np.asarray(target_arr_mic_stft)\n",
    "    target_arr_imu_stft = np.asarray(target_arr_imu_stft)\n",
    "    label_arr = np.asarray(label_arr)\n",
    "    target_mic_arr = np.asarray(target_mic_arr)\n",
    "    noise_arr = np.asarray(noise_arr)\n",
    "    noisy_mic_arr = np.asarray(noisy_mic_arr)\n",
    "\n",
    "\n",
    "    noisy_arr_stft = noisy_arr_stft.reshape(noisy_arr_stft.shape[0], noisy_arr_stft.shape[1], noisy_arr_stft.shape[2], 1)\n",
    "\n",
    "    target_arr_mic_stft = target_arr_mic_stft.reshape(target_arr_mic_stft.shape[0], target_arr_mic_stft.shape[1], target_arr_mic_stft.shape[2], 1)\n",
    "    target_arr_imu_stft = target_arr_imu_stft.reshape(target_arr_imu_stft.shape[0], target_arr_imu_stft.shape[1], target_arr_imu_stft.shape[2], 1)\n",
    "\n",
    "    output = np.abs(target_arr_mic_stft)\n",
    "\n",
    "\n",
    "    return noisy_arr_stft, np.abs(target_arr_imu_stft), output, label_arr, target_mic_arr, noise_arr, noisy_mic_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-4c274e62b29b>:22: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  indxs = np.asarray(indxs)\n"
     ]
    }
   ],
   "source": [
    "test_batch_size = 100\n",
    "noisy_audio, input_imu, clean_audio, labels, target_mic_arr, noise_arr, noisy_mic_arr = dataset_gen(batch_size=test_batch_size, ftype=\"test\")\n",
    "# print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label dictionary for KWS10\n",
    "label_dict = {'bird': 1,\n",
    " 'happy': 1,\n",
    " 'cat': 1,\n",
    " 'dog': 1,\n",
    " 'follow': 1,\n",
    " 'house': 1,\n",
    " 'forward': 1,\n",
    " 'bed': 1,\n",
    " 'backward': 1,\n",
    " 'sheila': 1,\n",
    " 'tree': 1,\n",
    " 'two': 1,\n",
    " 'down': 5,\n",
    " 'four': 1,\n",
    " 'eight': 1,\n",
    " 'visual': 1,\n",
    " 'five': 1,\n",
    " 'marvin': 1,\n",
    " 'go': 11,\n",
    " 'learn': 1,\n",
    " 'wow': 1,\n",
    " 'left': 6,\n",
    " 'one': 1,\n",
    " 'seven': 1,\n",
    " 'off': 9,\n",
    " 'nine': 1,\n",
    " 'right': 7,\n",
    " 'up': 4,\n",
    " 'stop': 10,\n",
    " 'zero': 1,\n",
    " 'three': 1,\n",
    " 'on': 8,\n",
    " 'yes': 2,\n",
    " 'six': 1,\n",
    " 'no': 3,\n",
    " '_silence_': 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 left\n"
     ]
    }
   ],
   "source": [
    "print(label_dict[labels[0][0]],  labels[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "THY-sZMiQ4UV"
   },
   "source": [
    "## Create the models\n",
    "\n",
    "Both the generator and discriminator are defined using the [Keras Sequential API](https://www.tensorflow.org/guide/keras#sequential_model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_denoiser(l2_strength):\n",
    "    \n",
    "    \n",
    "    input_imu = Input(shape=[20,21, 1])\n",
    "    input_audio = Input(shape=[200,21,1])\n",
    "\n",
    "    x = input_audio\n",
    "    y = input_imu\n",
    "    \n",
    "\n",
    "    # ----- Concatenate Modalities\n",
    "    x = tf.concat([x, y], axis=1)\n",
    "    \n",
    "    \n",
    "\n",
    "    # -----\n",
    "    x = Conv2D(filters=32, kernel_size=[7,1], strides=[1, 1], padding='same', use_bias=False,\n",
    "              kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = Conv2D(filters=64, kernel_size=[9,1], strides=[1, 1], padding='same', use_bias=False,\n",
    "                 kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = Conv2D(filters=32, kernel_size=[9,1], strides=[1, 1], padding='same', use_bias=False,\n",
    "              kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    print(x.shape)\n",
    "\n",
    "\n",
    "    # -----\n",
    "    # x = tf.keras.layers.ZeroPadding2D(((4,4), (0,0)))(x)\n",
    "    x = Conv2D(filters=32, kernel_size=[7,1], strides=[1, 1], padding='same', use_bias=False,\n",
    "              kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n",
    "\n",
    "    x = Activation('relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    skip0 = Conv2D(filters=64, kernel_size=[5,1], strides=[1, 1], padding='same', use_bias=False,\n",
    "                 kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n",
    "\n",
    "\n",
    "    x = Activation('relu')(skip0)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = Conv2D(filters=32, kernel_size=[7,1], strides=[1, 1], padding='same', use_bias=False,\n",
    "              kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n",
    "\n",
    "\n",
    "    x = Activation('relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    # -----\n",
    "    x = Conv2D(filters=32, kernel_size=[7,1], strides=[1, 1], padding='same', use_bias=False,\n",
    "              kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n",
    "    # x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    skip1 = Conv2D(filters=64, kernel_size=[5,1], strides=[1, 1], padding='same', use_bias=False,\n",
    "                 kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n",
    "    # x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(skip1)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = Conv2D(filters=32, kernel_size=[7,1], strides=[1, 1], padding='same', use_bias=False,\n",
    "              kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n",
    "    # x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    # ----\n",
    "    x = Conv2D(filters=32, kernel_size=[9,1], strides=[1, 1], padding='same', use_bias=False,\n",
    "              kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n",
    "    # x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = Conv2D(filters=64, kernel_size=[5,1], strides=[1, 1], padding='same', use_bias=False,\n",
    "              kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n",
    "    # x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = Conv2D(filters=32, kernel_size=[9,1], strides=[1, 1], padding='same', use_bias=False,\n",
    "              kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n",
    "    # x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    # ----\n",
    "    x = Conv2D(filters=32, kernel_size=[9,1], strides=[1, 1], padding='same', use_bias=False,\n",
    "              kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n",
    "    # x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = Conv2D(filters=64, kernel_size=[5,1], strides=[1, 1], padding='same', use_bias=False,\n",
    "             kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n",
    "    x = x + skip1\n",
    "    # x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = Conv2D(filters=32, kernel_size=[9,1], strides=[1, 1], padding='same', use_bias=False,\n",
    "              kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n",
    "    # x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    # ----\n",
    "    x = Conv2D(filters=32, kernel_size=[9,1], strides=[1, 1], padding='same', use_bias=False,\n",
    "              kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n",
    "    # x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = Conv2D(filters=64, kernel_size=[5,1], strides=[1, 1], padding='same', use_bias=False,\n",
    "             kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n",
    "    x = x + skip0\n",
    "    # x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = Conv2D(filters=32, kernel_size=[9,1], strides=[1, 1], padding='same', use_bias=False,\n",
    "              kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n",
    "#     x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    # ----\n",
    "    x = tf.keras.layers.SpatialDropout2D(0.2)(x)\n",
    "    x = Conv2D(filters=1, kernel_size=[21,1], strides=[1, 1], padding='valid')(x)\n",
    "\n",
    "    denoiser = Model(inputs=[input_audio, input_imu], outputs=x)    \n",
    "    \n",
    "    return denoiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 220, 21, 32)\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 200, 21, 1)  0           []                               \n",
      "                                ]                                                                 \n",
      "                                                                                                  \n",
      " input_1 (InputLayer)           [(None, 20, 21, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " tf.concat (TFOpLambda)         (None, 220, 21, 1)   0           ['input_2[0][0]',                \n",
      "                                                                  'input_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 220, 21, 32)  224         ['tf.concat[0][0]']              \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 220, 21, 32)  0           ['conv2d[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 220, 21, 32)  128        ['activation[0][0]']             \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 220, 21, 64)  18432       ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 220, 21, 64)  0           ['conv2d_1[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 220, 21, 64)  256        ['activation_1[0][0]']           \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 220, 21, 32)  18432       ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 220, 21, 32)  0           ['conv2d_2[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 220, 21, 32)  128        ['activation_2[0][0]']           \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 220, 21, 32)  7168        ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 220, 21, 32)  0           ['conv2d_3[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 220, 21, 32)  128        ['activation_3[0][0]']           \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 220, 21, 64)  10240       ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 220, 21, 64)  0           ['conv2d_4[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 220, 21, 64)  256        ['activation_4[0][0]']           \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 220, 21, 32)  14336       ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 220, 21, 32)  0           ['conv2d_5[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 220, 21, 32)  128        ['activation_5[0][0]']           \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 220, 21, 32)  7168        ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 220, 21, 32)  0           ['conv2d_6[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 220, 21, 32)  128        ['activation_6[0][0]']           \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 220, 21, 64)  10240       ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 220, 21, 64)  0           ['conv2d_7[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 220, 21, 64)  256        ['activation_7[0][0]']           \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 220, 21, 32)  14336       ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 220, 21, 32)  0           ['conv2d_8[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 220, 21, 32)  128        ['activation_8[0][0]']           \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 220, 21, 32)  9216        ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 220, 21, 32)  0           ['conv2d_9[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 220, 21, 32)  128        ['activation_9[0][0]']           \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 220, 21, 64)  10240       ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 220, 21, 64)  0           ['conv2d_10[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 220, 21, 64)  256        ['activation_10[0][0]']          \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 220, 21, 32)  18432       ['batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, 220, 21, 32)  0           ['conv2d_11[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 220, 21, 32)  128        ['activation_11[0][0]']          \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 220, 21, 32)  9216        ['batch_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " activation_12 (Activation)     (None, 220, 21, 32)  0           ['conv2d_12[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 220, 21, 32)  128        ['activation_12[0][0]']          \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 220, 21, 64)  10240       ['batch_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " tf.__operators__.add (TFOpLamb  (None, 220, 21, 64)  0          ['conv2d_13[0][0]',              \n",
      " da)                                                              'conv2d_7[0][0]']               \n",
      "                                                                                                  \n",
      " activation_13 (Activation)     (None, 220, 21, 64)  0           ['tf.__operators__.add[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 220, 21, 64)  256        ['activation_13[0][0]']          \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 220, 21, 32)  18432       ['batch_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " activation_14 (Activation)     (None, 220, 21, 32)  0           ['conv2d_14[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 220, 21, 32)  128        ['activation_14[0][0]']          \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 220, 21, 32)  9216        ['batch_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " activation_15 (Activation)     (None, 220, 21, 32)  0           ['conv2d_15[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 220, 21, 32)  128        ['activation_15[0][0]']          \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 220, 21, 64)  10240       ['batch_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " tf.__operators__.add_1 (TFOpLa  (None, 220, 21, 64)  0          ['conv2d_16[0][0]',              \n",
      " mbda)                                                            'conv2d_4[0][0]']               \n",
      "                                                                                                  \n",
      " activation_16 (Activation)     (None, 220, 21, 64)  0           ['tf.__operators__.add_1[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 220, 21, 64)  256        ['activation_16[0][0]']          \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 220, 21, 32)  18432       ['batch_normalization_16[0][0]'] \n",
      "                                                                                                  \n",
      " activation_17 (Activation)     (None, 220, 21, 32)  0           ['conv2d_17[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, 220, 21, 32)  128        ['activation_17[0][0]']          \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " spatial_dropout2d (SpatialDrop  (None, 220, 21, 32)  0          ['batch_normalization_17[0][0]'] \n",
      " out2D)                                                                                           \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 200, 21, 1)   673         ['spatial_dropout2d[0][0]']      \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 217,985\n",
      "Trainable params: 216,449\n",
      "Non-trainable params: 1,536\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "denoiser = make_denoiser(l2_strength=0.002)\n",
    "denoiser.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 21, 1)\n"
     ]
    }
   ],
   "source": [
    "denoised_audio = denoiser([np.abs(noisy_audio), input_imu])\n",
    "print(denoised_audio[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_translator():\n",
    "    input_imu = Input(shape=[20,21, 1])\n",
    "    \n",
    "    # Encoder\n",
    "    x = Conv2D(filters=128, kernel_size=3,padding='same', name=\"enc_conv1\")(input_imu)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    x = Conv2D(filters=32, kernel_size=3, strides=1, padding='same', name=\"enc_conv2\")(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D((5,1), name=\"enc_maxpool1\")(x)\n",
    "    \n",
    "    x = Conv2D(filters=16, kernel_size=3, strides=1, padding='same', name=\"enc_conv3\")(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    \n",
    "    # Decoder\n",
    "    x = Conv2D(filters=16, kernel_size=3, strides=1, padding='same', name=\"dec_conv1\")(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "    x = UpSampling2D((2,1), name=\"dec_up1\")(x)\n",
    "#     up1 = Conv2D(filters=1, kernel_size=3,  padding='same', name=\"up1\")(x)\n",
    "    \n",
    "    x = Conv2D(filters=32, kernel_size=3, strides=1, padding='same', name=\"dec_conv2\")(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "    \n",
    "    x = Conv2D(filters=1, kernel_size=3,  padding='same', name=\"dec_conv3\")(x)\n",
    "    x = UpSampling2D((5,1), name=\"dec_up2\")(x)\n",
    "    up2 = Conv2D(filters=1, kernel_size=3,  padding='same', name=\"up2\")(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "\n",
    "    x = Conv2D(filters=64, kernel_size=3, strides=1, padding='same', name=\"dec_conv4\")(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = UpSampling2D((5,1), name=\"dec_up3\")(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "\n",
    "    x = Conv2D(filters=128, kernel_size=3, strides=1, padding='same', name=\"dec_conv5\")(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    x = Conv2D(filters=1, kernel_size=3, padding='same', name=\"dec_conv6\")(x)\n",
    "\n",
    "    translator = Model(inputs=input_imu, outputs=[up2, x])  #outputs=[up1, up2, x])    \n",
    "    \n",
    "    return translator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 20, 21, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " enc_conv1 (Conv2D)             (None, 20, 21, 128)  1280        ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " activation_18 (Activation)     (None, 20, 21, 128)  0           ['enc_conv1[0][0]']              \n",
      "                                                                                                  \n",
      " enc_conv2 (Conv2D)             (None, 20, 21, 32)   36896       ['activation_18[0][0]']          \n",
      "                                                                                                  \n",
      " activation_19 (Activation)     (None, 20, 21, 32)   0           ['enc_conv2[0][0]']              \n",
      "                                                                                                  \n",
      " enc_maxpool1 (MaxPooling2D)    (None, 4, 21, 32)    0           ['activation_19[0][0]']          \n",
      "                                                                                                  \n",
      " enc_conv3 (Conv2D)             (None, 4, 21, 16)    4624        ['enc_maxpool1[0][0]']           \n",
      "                                                                                                  \n",
      " activation_20 (Activation)     (None, 4, 21, 16)    0           ['enc_conv3[0][0]']              \n",
      "                                                                                                  \n",
      " dec_conv1 (Conv2D)             (None, 4, 21, 16)    2320        ['activation_20[0][0]']          \n",
      "                                                                                                  \n",
      " activation_21 (Activation)     (None, 4, 21, 16)    0           ['dec_conv1[0][0]']              \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 4, 21, 16)    0           ['activation_21[0][0]']          \n",
      "                                                                                                  \n",
      " dec_up1 (UpSampling2D)         (None, 8, 21, 16)    0           ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dec_conv2 (Conv2D)             (None, 8, 21, 32)    4640        ['dec_up1[0][0]']                \n",
      "                                                                                                  \n",
      " activation_22 (Activation)     (None, 8, 21, 32)    0           ['dec_conv2[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 8, 21, 32)    0           ['activation_22[0][0]']          \n",
      "                                                                                                  \n",
      " dec_conv3 (Conv2D)             (None, 8, 21, 1)     289         ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " dec_up2 (UpSampling2D)         (None, 40, 21, 1)    0           ['dec_conv3[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 40, 21, 1)    0           ['dec_up2[0][0]']                \n",
      "                                                                                                  \n",
      " dec_conv4 (Conv2D)             (None, 40, 21, 64)   640         ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " activation_23 (Activation)     (None, 40, 21, 64)   0           ['dec_conv4[0][0]']              \n",
      "                                                                                                  \n",
      " dec_up3 (UpSampling2D)         (None, 200, 21, 64)  0           ['activation_23[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 200, 21, 64)  0           ['dec_up3[0][0]']                \n",
      "                                                                                                  \n",
      " dec_conv5 (Conv2D)             (None, 200, 21, 128  73856       ['dropout_3[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " activation_24 (Activation)     (None, 200, 21, 128  0           ['dec_conv5[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " up2 (Conv2D)                   (None, 40, 21, 1)    10          ['dec_up2[0][0]']                \n",
      "                                                                                                  \n",
      " dec_conv6 (Conv2D)             (None, 200, 21, 1)   1153        ['activation_24[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 125,708\n",
      "Trainable params: 125,708\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "translator = make_translator()\n",
    "translator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 40, 21, 1)\n"
     ]
    }
   ],
   "source": [
    "translated_audio = translator(input_imu)\n",
    "\n",
    "print(translated_audio[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stft2time(target_stft, noisy_audio):\n",
    "    theta_n = np.angle(noisy_audio.reshape(noisy_audio.shape[0], noisy_audio.shape[1]))\n",
    "    x = target_stft.reshape([target_stft.shape[0], target_stft.shape[1]])\n",
    "    complex_noisy = x * np.exp(1j*theta_n)\n",
    "    \n",
    "    temp_z = np.zeros([1,21])\n",
    "    temp = np.hstack((temp_z.T, complex_noisy.T)).T\n",
    "    reconstructed_noisy_mic = librosa.istft(temp, hop_length=200, length=4000)\n",
    "    return reconstructed_noisy_mic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_mask(translator_output, noisy_or_denoiser_output, percentile1, percentile2):\n",
    "    d_prev_out = noisy_or_denoiser_output.reshape([200, 21])\n",
    "    t_out = translator_output.reshape([200,21])\n",
    "    \n",
    "    d_prev_db = librosa.amplitude_to_db(d_prev_out,ref=80)\n",
    "    t_db =librosa.amplitude_to_db(t_out,ref=80)\n",
    "\n",
    "    summing = np.percentile(d_prev_db, percentile1, axis = 0)\n",
    "    \n",
    "    ref = (np.max(summing)+np.min(summing))/2\n",
    "    ref_id = np.where(summing>ref)\n",
    "\n",
    "    arr = np.arange(0, 21)\n",
    "    c=np.abs([arr-x for x in ref_id[0]])\n",
    "    c = np.min(c,axis=0)\n",
    "\n",
    "    idx = np.where(c>margin)\n",
    "\n",
    "    truncated_t = t_db.reshape([200,21])[:, idx]\n",
    "    \n",
    "    for j in range(0, 4):\n",
    "        target_data = truncated_t[j*50: j*50+50]\n",
    "        thr = np.percentile(target_data, percentile2)\n",
    "        t_sig = tf.math.sigmoid(t_db[j*50: j*50+50]-thr)\n",
    "        if j == 0:\n",
    "            stiched_data = t_sig\n",
    "        else:\n",
    "            stiched_data = np.concatenate([stiched_data, t_sig], axis=0)\n",
    "\n",
    "\n",
    "    mask = noisy_or_denoiser_output.reshape([200,21]) * stiched_data\n",
    "    \n",
    "    \n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "translator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "denoiser_optimizer = tf.keras.optimizers.Adam(1e-3)\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(translator_optimizer=translator_optimizer,\n",
    "                                 denoiser_optimizer=denoiser_optimizer,\n",
    "                                 translator=translator,\n",
    "                                 denoiser=denoiser)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KWS_10 Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from kws_streaming.models import model_params\n",
    "from kws_streaming.models import model_flags\n",
    "from kws_streaming.models import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import kws_streaming.data.input_data as input_data\n",
    "#import tensorflow.compat.v1 as tf\n",
    "def kws_set_flag():\n",
    "    \n",
    "    current_dir = os.getcwd()\n",
    "    MODEL_NAME = 'ds_tc_resnet'\n",
    "    # MODEL_NAME = 'svdf'\n",
    "    MODELS_PATH = os.path.join(current_dir, \"models\")\n",
    "    MODEL_PATH = os.path.join(MODELS_PATH, MODEL_NAME + \"_40k/\")\n",
    "    MODEL_PATH\n",
    "    FLAGS = model_params.HOTWORD_MODEL_PARAMS[MODEL_NAME]\n",
    "\n",
    "    # set speech feature extractor properties\n",
    "\n",
    "    FLAGS.window_size_ms = 30.0\n",
    "    FLAGS.window_stride_ms = 10.0\n",
    "    FLAGS.mel_num_bins = 80\n",
    "    FLAGS.dct_num_features = 40\n",
    "    FLAGS.feature_type = 'mfcc_tf'\n",
    "    FLAGS.preprocess = 'raw'\n",
    "\n",
    "    # for numerical correctness of streaming and non streaming models set it to 1\n",
    "    # but for real use case streaming set it to 0\n",
    "    FLAGS.causal_data_frame_padding = 0\n",
    "\n",
    "    FLAGS.use_tf_fft = True\n",
    "    FLAGS.mel_non_zero_only = not FLAGS.use_tf_fft\n",
    "\n",
    "    # set training settings\n",
    "    FLAGS.train = 1\n",
    "    # reduced number of training steps for test only\n",
    "    # so model accuracy will be low,\n",
    "    # to improve accuracy set how_many_training_steps = '40000,40000,20000,20000'\n",
    "    FLAGS.how_many_training_steps = '40000,40000,20000,20000'\n",
    "    FLAGS.learning_rate = '0.001,0.0005,0.0001,0.00002'\n",
    "    FLAGS.lr_schedule = 'linear'\n",
    "\n",
    "    # data augmentation parameters\n",
    "    FLAGS.resample = 0.15\n",
    "    FLAGS.time_shift_ms = 100\n",
    "    FLAGS.use_spec_augment = 1\n",
    "    FLAGS.time_masks_number = 2\n",
    "    FLAGS.time_mask_max_size = 25\n",
    "    FLAGS.frequency_masks_number = 2\n",
    "    FLAGS.frequency_mask_max_size = 7\n",
    "    FLAGS.pick_deterministically = 1\n",
    "    \n",
    "    FLAGS.train_dir = MODEL_PATH\n",
    "    FLAGS.sample_rate = 4000\n",
    "    FLAGS.mel_upper_edge_hertz = 2000\n",
    "    FLAGS.model_name = MODEL_NAME\n",
    "    if MODEL_NAME == 'ds_tc_resnet':\n",
    "      # it is an example of model streaming with strided convolution, strided pooling and dilated convolution\n",
    "      FLAGS.activation = 'relu'\n",
    "      FLAGS.dropout = 0.0\n",
    "      FLAGS.ds_filters = '128, 64, 64, 64, 128, 128'\n",
    "      FLAGS.ds_filter_separable = '1, 1, 1, 1, 1, 1'\n",
    "      FLAGS.ds_repeat = '1, 1, 1, 1, 1, 1'\n",
    "      FLAGS.ds_residual = '0, 1, 1, 1, 0, 0' # residual can not be applied with stride\n",
    "    #   FLAGS.ds_kernel_size = '11, 5, 15, 7, 29, 1'\n",
    "      FLAGS.ds_kernel_size = '11, 5, 15, 17, 15, 1'\n",
    "      FLAGS.ds_dilation = '1, 1, 1, 1, 2, 1'\n",
    "      FLAGS.ds_stride = '1, 1, 1, 1, 1, 1'\n",
    "      FLAGS.ds_pool = '1, 2, 1, 1, 1, 1'\n",
    "      FLAGS.ds_padding = \"'causal', 'causal', 'causal', 'causal', 'causal', 'causal'\"\n",
    "    FLAGS.clip_duration_ms = 1000  # standard audio file in this data set has 1 sec length\n",
    "    FLAGS.batch_size = 100\n",
    "    flags = model_flags.update_flags(FLAGS)\n",
    "    return flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:There is no need to use Stream on time dim with size 1\n"
     ]
    }
   ],
   "source": [
    "flags = kws_set_flag()\n",
    "flags.batch_size=1\n",
    "\n",
    "kws_model = models.MODELS[flags.model_name](flags)\n",
    "weights_name='best_weights'\n",
    "kws_model.load_weights(os.path.join(flags.train_dir,weights_name)).expect_partial()\n",
    "kws_model.compile(run_eagerly = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tensorflow/python/data/ops/dataset_ops.py:4526: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KWS35 Accuracy:  0.89\n"
     ]
    }
   ],
   "source": [
    "latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "checkpoint.restore(latest)\n",
    "\n",
    "normalized_test_imu = (input_imu/np.max(input_imu.reshape([test_batch_size, 20, 21])))*np.max(np.max(np.abs(noisy_audio).reshape([test_batch_size, 200, 21])))\n",
    "denoised_static = checkpoint.denoiser([np.abs(noisy_audio), normalized_test_imu], training=False).numpy()\n",
    "\n",
    "denoised_correct_classification = 0\n",
    "for i in range(0, test_batch_size):\n",
    "    reconstructed_denoised_mic = stft2time(denoised_static[i], noisy_audio[i])\n",
    "    predictions = kws_model.predict(reconstructed_denoised_mic.reshape([1,4000]))\n",
    "    predicted_labels = np.argmax(predictions, axis=1)[0]\n",
    "\n",
    "    if predicted_labels == label_dict[labels[i][0]]:\n",
    "        denoised_correct_classification += 1\n",
    "print(\"KWS35 Accuracy: \", str(round(denoised_correct_classification/test_batch_size, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rfM4YcPVPkNO"
   },
   "source": [
    "# KWS35 Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict_35 ={'follow': 35,\n",
    " 'learn': 4,\n",
    " 'backward': 5,\n",
    " 'visual': 2,\n",
    " 'dog': 6,\n",
    " 'cat': 34,\n",
    " 'house': 27,\n",
    " 'bird': 21,\n",
    " 'bed': 13,\n",
    " 'tree': 17,\n",
    " 'eight': 23,\n",
    " 'marvin': 28,\n",
    " 'five': 30,\n",
    " 'go': 11,\n",
    " 'no': 24,\n",
    " 'forward': 26,\n",
    " 'down': 33,\n",
    " 'four': 20,\n",
    " 'seven': 18,\n",
    " 'wow': 3,\n",
    " 'on': 19,\n",
    " 'zero': 16,\n",
    " 'up': 12,\n",
    " 'three': 32,\n",
    " 'six': 25,\n",
    " 'left': 8,\n",
    " 'happy': 9,\n",
    " 'sheila': 29,\n",
    " 'right': 22,\n",
    " 'nine': 10,\n",
    " 'one': 15,\n",
    " 'off': 31,\n",
    " 'two': 7,\n",
    " 'yes': 36,\n",
    " 'stop': 14,\n",
    " '_silence_': 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kws_set_flag_35():\n",
    "    \n",
    "    current_dir = os.getcwd()\n",
    "    MODEL_NAME = 'ds_tc_resnet'\n",
    "    # MODEL_NAME = 'svdf'\n",
    "    MODELS_PATH = os.path.join(current_dir, \"models\")\n",
    "    MODEL_PATH = os.path.join(MODELS_PATH, MODEL_NAME + \"_40k_fs_4k_35L/\")\n",
    "    MODEL_PATH\n",
    "    FLAGS = model_params.HOTWORD_MODEL_PARAMS[MODEL_NAME]\n",
    "\n",
    "    # set speech feature extractor properties\n",
    "\n",
    "    FLAGS.window_size_ms = 30.0\n",
    "    FLAGS.window_stride_ms = 10.0\n",
    "    FLAGS.mel_num_bins = 80\n",
    "    FLAGS.dct_num_features = 40\n",
    "    FLAGS.feature_type = 'mfcc_tf'\n",
    "    FLAGS.preprocess = 'raw'\n",
    "\n",
    "    # for numerical correctness of streaming and non streaming models set it to 1\n",
    "    # but for real use case streaming set it to 0\n",
    "    FLAGS.causal_data_frame_padding = 0\n",
    "\n",
    "    FLAGS.use_tf_fft = True\n",
    "    FLAGS.mel_non_zero_only = not FLAGS.use_tf_fft\n",
    "\n",
    "    # set training settings\n",
    "    FLAGS.train = 1\n",
    "    # reduced number of training steps for test only\n",
    "    # so model accuracy will be low,\n",
    "    # to improve accuracy set how_many_training_steps = '40000,40000,20000,20000'\n",
    "    FLAGS.how_many_training_steps = '40000,40000,20000,20000'\n",
    "    FLAGS.learning_rate = '0.001,0.0005,0.0001,0.00002'\n",
    "    FLAGS.lr_schedule = 'linear'\n",
    "\n",
    "    # data augmentation parameters\n",
    "    FLAGS.resample = 0.15\n",
    "    FLAGS.time_shift_ms = 100\n",
    "    FLAGS.use_spec_augment = 1\n",
    "    FLAGS.time_masks_number = 2\n",
    "    FLAGS.time_mask_max_size = 25\n",
    "    FLAGS.frequency_masks_number = 2\n",
    "    FLAGS.frequency_mask_max_size = 7\n",
    "    FLAGS.pick_deterministically = 1\n",
    "    \n",
    "    FLAGS.train_dir = MODEL_PATH\n",
    "    FLAGS.sample_rate = 4000\n",
    "    FLAGS.mel_upper_edge_hertz = 2000\n",
    "    FLAGS.model_name = MODEL_NAME\n",
    "    if MODEL_NAME == 'ds_tc_resnet':\n",
    "      # it is an example of model streaming with strided convolution, strided pooling and dilated convolution\n",
    "      FLAGS.activation = 'relu'\n",
    "      FLAGS.dropout = 0.0\n",
    "      FLAGS.ds_filters = '128, 64, 64, 64, 128, 128'\n",
    "      FLAGS.ds_filter_separable = '1, 1, 1, 1, 1, 1'\n",
    "      FLAGS.ds_repeat = '1, 1, 1, 1, 1, 1'\n",
    "      FLAGS.ds_residual = '0, 1, 1, 1, 0, 0' # residual can not be applied with stride\n",
    "    #   FLAGS.ds_kernel_size = '11, 5, 15, 7, 29, 1'\n",
    "      FLAGS.ds_kernel_size = '11, 5, 15, 17, 15, 1'\n",
    "      FLAGS.ds_dilation = '1, 1, 1, 1, 2, 1'\n",
    "      FLAGS.ds_stride = '1, 1, 1, 1, 1, 1'\n",
    "      FLAGS.ds_pool = '1, 2, 1, 1, 1, 1'\n",
    "      FLAGS.ds_padding = \"'causal', 'causal', 'causal', 'causal', 'causal', 'causal'\"\n",
    "    FLAGS.clip_duration_ms = 1000  # standard audio file in this data set has 1 sec length\n",
    "    FLAGS.batch_size = 100\n",
    "    FLAGS.wanted_words = 'visual,wow,learn,backward,dog,two,left,happy,nine,go,up,bed,stop,one,zero,tree,seven,on,four,bird,right,eight,no,six,forward,house,marvin,sheila,five,off,three,down,cat,follow,yes'\n",
    "    flags = model_flags.update_flags(FLAGS)\n",
    "    return flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:There is no need to use Stream on time dim with size 1\n"
     ]
    }
   ],
   "source": [
    "flags_35 = kws_set_flag_35()\n",
    "flags_35.batch_size=1\n",
    "\n",
    "kws_model = models.MODELS[flags_35.model_name](flags_35)\n",
    "weights_name='best_weights'\n",
    "kws_model.load_weights(os.path.join(flags_35.train_dir,weights_name)).expect_partial()\n",
    "kws_model.compile(run_eagerly = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KWS35 Accuracy:  0.82\n"
     ]
    }
   ],
   "source": [
    "latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "checkpoint.restore(latest)\n",
    "\n",
    "normalized_test_imu = (input_imu/np.max(input_imu.reshape([test_batch_size, 20, 21])))*np.max(np.max(np.abs(noisy_audio).reshape([test_batch_size, 200, 21])))\n",
    "denoised_static = checkpoint.denoiser([np.abs(noisy_audio), normalized_test_imu], training=False).numpy()\n",
    "\n",
    "denoised_correct_classification = 0\n",
    "for i in range(0, test_batch_size):\n",
    "    reconstructed_denoised_mic = stft2time(denoised_static[i], noisy_audio[i])\n",
    "    predictions = kws_model.predict(reconstructed_denoised_mic.reshape([1,4000]))\n",
    "    predicted_labels = np.argmax(predictions, axis=1)[0]\n",
    "\n",
    "    if predicted_labels == label_dict_35[labels[i][0]]:\n",
    "        denoised_correct_classification += 1\n",
    "print(\"KWS35 Accuracy: \", str(round(denoised_correct_classification/test_batch_size, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "dcgan.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
